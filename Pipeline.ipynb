{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224510b2",
   "metadata": {},
   "source": [
    "# Bonita Task 2A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb813d5b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import random as r\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e34dc",
   "metadata": {},
   "source": [
    "## Logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad546fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_api_key = ...\n",
    "openai_api_key = ...\n",
    "login(hf_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9575e2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da84f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Template(yaml.YAMLObject):\n",
    "    yaml_tag = u'!Template'\n",
    "\n",
    "    def __init__(self, answer_choices, id, jinja, metadata, name, reference):\n",
    "        self.answer_choices = answer_choices\n",
    "        self.id = id\n",
    "        self.jinja = jinja\n",
    "        self.metadata = metadata\n",
    "        self.name = name \n",
    "        self.reference = reference\n",
    "\n",
    "\n",
    "class TemplateMetadata(yaml.YAMLObject):\n",
    "    yaml_tag = u'!TemplateMetadata'\n",
    "\n",
    "    def __init__(self, choices_in_prompt, languages, metrics, original_task):\n",
    "        self.choices_in_prompt = choices_in_prompt\n",
    "        self.languages = languages\n",
    "        self.metrics = metrics\n",
    "        self.original_task = original_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace8a3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>dataset_config_name</th>\n",
       "      <th>template_name</th>\n",
       "      <th>task_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>context_answer_to_question</td>\n",
       "      <td>question generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>description_context_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>description_context_question_text</td>\n",
       "      <td>question answering without choices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>description_context_question_answer_id</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cosmos_qa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>context_description_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name dataset_config_name                             template_name  \\\n",
       "0    cosmos_qa                 NaN                context_answer_to_question   \n",
       "1    cosmos_qa                 NaN  description_context_question_answer_text   \n",
       "2    cosmos_qa                 NaN         description_context_question_text   \n",
       "3    cosmos_qa                 NaN    description_context_question_answer_id   \n",
       "4    cosmos_qa                 NaN  context_description_question_answer_text   \n",
       "\n",
       "                            task_type  \n",
       "0                 question generation  \n",
       "1  multiple-choice question answering  \n",
       "2  question answering without choices  \n",
       "3  multiple-choice question answering  \n",
       "4  multiple-choice question answering  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bonito_prompts_task_types.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad779458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dataset_config_name'].fillna('', inplace=True)\n",
    "filename = df['dataset_name'] + '_' + df['dataset_config_name'] + '.yaml'\n",
    "for i in range(len(filename)):\n",
    "    filename[i] = filename[i].replace('_.', '.')\n",
    "df['filename'] = filename\n",
    "df.drop(columns=['dataset_name','dataset_config_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4085fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>original_template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context_answer_to_question</td>\n",
       "      <td>question generation</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>description_context_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>description_context_question_text</td>\n",
       "      <td>question answering without choices</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>description_context_question_answer_id</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context_description_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              template_name  \\\n",
       "0                context_answer_to_question   \n",
       "1  description_context_question_answer_text   \n",
       "2         description_context_question_text   \n",
       "3    description_context_question_answer_id   \n",
       "4  context_description_question_answer_text   \n",
       "\n",
       "                            task_type        filename original_template  \n",
       "0                 question generation  cosmos_qa.yaml                    \n",
       "1  multiple-choice question answering  cosmos_qa.yaml                    \n",
       "2  question answering without choices  cosmos_qa.yaml                    \n",
       "3  multiple-choice question answering  cosmos_qa.yaml                    \n",
       "4  multiple-choice question answering  cosmos_qa.yaml                    "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_template'] = ''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3b4e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filenames = df.groupby('filename')['template_name'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e896da",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_id_mapping = {}\n",
    "\n",
    "for key in dict_filenames.keys():\n",
    "    with open(f'databases/{key}') as f:\n",
    "        data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        for t in data['templates'].keys():\n",
    "            name_template = data['templates'][t].name\n",
    "            if name_template in dict_filenames[key]:\n",
    "                original_template = data['templates'][t].jinja\n",
    "                df.loc[(df['filename'] == key) & (df['template_name'] == name_template), \n",
    "                       'original_template'] = original_template\n",
    "\n",
    "                template_rows = df[(df['filename'] == key) & (df['template_name'] == name_template)]\n",
    "                if not template_rows.empty:\n",
    "                    task_type = template_rows['task_type'].iloc[0]\n",
    "                    template_id = data['templates'][t].id\n",
    "                    template_id_mapping[template_id] = f\"{name_template}+{task_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311971da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bonito_metatemplates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc196",
   "metadata": {},
   "source": [
    "## Human Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb22c0",
   "metadata": {},
   "source": [
    "Human translations were performed by the authors.\n",
    "The translated meta-templates were added manually to the dataframe in the column: 'human_translation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e649432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>filename</th>\n",
       "      <th>original_template</th>\n",
       "      <th>human_translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context_answer_to_question</td>\n",
       "      <td>question generation</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td>Based on the context and the answer, generate ...</td>\n",
       "      <td>Basandoti sul contesto e sulla risposta, gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>description_context_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td>Read the following context and choose the best...</td>\n",
       "      <td>Leggi il seguente contesto e scegli l'opzione ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>description_context_question_text</td>\n",
       "      <td>question answering without choices</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td>Read the following context and answer the ques...</td>\n",
       "      <td>Leggi il seguente contesto e rispondi alla dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>description_context_question_answer_id</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td>Read the following context and choose the best...</td>\n",
       "      <td>Leggi il seguente contesto e scegli l'opzione ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>context_description_question_answer_text</td>\n",
       "      <td>multiple-choice question answering</td>\n",
       "      <td>cosmos_qa.yaml</td>\n",
       "      <td>{{ context }}\\nAccording to the above context,...</td>\n",
       "      <td>{{ context }}\\nIn base al contesto in alto, sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              template_name  \\\n",
       "0                context_answer_to_question   \n",
       "1  description_context_question_answer_text   \n",
       "2         description_context_question_text   \n",
       "3    description_context_question_answer_id   \n",
       "4  context_description_question_answer_text   \n",
       "\n",
       "                            task_type        filename  \\\n",
       "0                 question generation  cosmos_qa.yaml   \n",
       "1  multiple-choice question answering  cosmos_qa.yaml   \n",
       "2  question answering without choices  cosmos_qa.yaml   \n",
       "3  multiple-choice question answering  cosmos_qa.yaml   \n",
       "4  multiple-choice question answering  cosmos_qa.yaml   \n",
       "\n",
       "                                   original_template  \\\n",
       "0  Based on the context and the answer, generate ...   \n",
       "1  Read the following context and choose the best...   \n",
       "2  Read the following context and answer the ques...   \n",
       "3  Read the following context and choose the best...   \n",
       "4  {{ context }}\\nAccording to the above context,...   \n",
       "\n",
       "                                   human_translation  \n",
       "0  Basandoti sul contesto e sulla risposta, gener...  \n",
       "1  Leggi il seguente contesto e scegli l'opzione ...  \n",
       "2  Leggi il seguente contesto e rispondi alla dom...  \n",
       "3  Leggi il seguente contesto e scegli l'opzione ...  \n",
       "4  {{ context }}\\nIn base al contesto in alto, sc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.read_csv('original_and_human.csv')\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fe7c9",
   "metadata": {},
   "source": [
    "## Machine Translation - GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de23e25",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_template = df['original_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8da538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_template(original_template):    \n",
    "    prompt = ChatPromptTemplate.from_messages([(\"human\", '''Translate this template from English to Italian. \n",
    "    Do not translate the placeholders (e.g. {{ context }}) and keep the escape characters.\n",
    "    Do not translate anything inside parentheses, unless it is between quotes (\"...\").\n",
    "    Do not add emojis. Do not add anything more than just the translation.\n",
    "    Do not make up new words. If you can't find the exact translation of a word\n",
    "    find another way to express the same concept.\n",
    "    Use the following as an example:\n",
    "    ENGLISH: {text}\n",
    "    ITALIAN:'''\n",
    ")])\n",
    "    model = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "    translate = prompt | model | StrOutputParser()\n",
    "    generation = translate.invoke({\"original_template\": original_template})\n",
    "    return generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_templates = []\n",
    "for i in range(len(df)):\n",
    "    #print(f\"{i+1}/{len(df)}\")\n",
    "    translated_templates.append(translate_template(original_template[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802350d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['gpt_zero_shot'] = translated_templates\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50b7ec8",
   "metadata": {},
   "source": [
    "### One-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ca052",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "for i in range(len(base_df)):\n",
    "    print(str(i+1)+'/323')\n",
    "    r.seed(seed)\n",
    "    example_n = r.randrange(0,105)\n",
    "    english_example = base_df['original_template'][example_n]\n",
    "    italian_example = base_df['human_translation'][example_n]\n",
    "    text = base_df['original_template'][i]\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"human\", '''Translate this template from English to Italian. \n",
    "    Do not translate the placeholders (e.g. {{ context }}) and keep the escape characters.\n",
    "    Do not translate anything inside parentheses, unless it is between quotes (\"...\").\n",
    "    Do not add emojis. Do not add anything more than just the translation.\n",
    "    Do not make up new words. If you can't find the exact translation of a word\n",
    "    find another way to express the same concept.\n",
    "    Use the following as an example:\n",
    "    EXAMPLE-ENGLISH:  {english_example} \n",
    "    EXAMPLE-ITALIAN:  {italian_example}\n",
    "    ENGLISH: {text}\n",
    "    ITALIAN: '''\n",
    "    )])\n",
    "    seed = r.randrange(0, 1000)\n",
    "    model = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "    translate = prompt | model | StrOutputParser()\n",
    "    generation = translate.invoke({\"english_example\":english_example, \"italian_example\":italian_example, \"text\":text})\n",
    "    translations.append(generation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e8fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['gpt_one_shot'] = translated_templates\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b77cf6",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metatemplate_sets = {'normal':[1,64,121,194,285],\n",
    "                     '{{\"answer\"}}':[130,167,229,241,299],\n",
    "                     'if-endif':[91,139,236,250,272],\n",
    "                     'ABCD':[14,17,64,68,70],\n",
    "                     'PARAPHRASE':[18,20,24,236,238]}\n",
    "examples_n=[]\n",
    "english_examples=[]\n",
    "italian_examples=[]\n",
    "\n",
    "for t in metatemplate_sets.keys():\n",
    "    examples_n.append(r.choice(metatemplate_sets[t]))\n",
    "\n",
    "for n in examples_n:\n",
    "    english_examples.append(base_df['original_template'][n])\n",
    "    italian_examples.append(base_df['human_translation'][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330efefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "for i in range(len(base_df['original_template'])):\n",
    "    print(str(i+1)+'/323')\n",
    "    r.seed(seed)\n",
    "\n",
    "    examples_n=[]\n",
    "\n",
    "    for t in metatemplate_sets.keys():\n",
    "        examples_n.append(r.choice(metatemplate_sets[t]))\n",
    "\n",
    "    for n in examples_n:\n",
    "        english_examples.append(base_df['original_template'][n])\n",
    "        italian_examples.append(base_df['human_translation'][n])\n",
    "    \n",
    "    text = base_df['original_template'][i]\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"human\", '''Consider the following examples\n",
    "    EXAMPLE-ENGLISH-1:  {english_examples[0]} \n",
    "    EXAMPLE-ITALIAN-1:  {italian_examples[0]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-2:  {english_examples[1]} \n",
    "    EXAMPLE-ITALIAN-2:  {italian_examples[1]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-3:  {english_examples[2]} \n",
    "    EXAMPLE-ITALIAN-3:  {italian_examples[2]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-4:  {english_examples[3]} \n",
    "    EXAMPLE-ITALIAN-4:  {italian_examples[3]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-5:  {english_examples[4]} \n",
    "    EXAMPLE-ITALIAN-5:  {italian_examples[4]}\n",
    "\n",
    "    Translate this template from English to Italian. \n",
    "    Do not add anything new. Translate only once.\n",
    "    ENGLISH: {text}\n",
    "    ITALIAN:\n",
    "    ''')])\n",
    "    seed = r.randrange(0, 1000)\n",
    "    model = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "    translate = prompt | model | StrOutputParser()\n",
    "    generation = translate.invoke({\"english_example[0]\":english_example[0], \"italian_example[0]\":italian_example[0],\n",
    "                                   \"english_example[1]\":english_example[1], \"italian_example[1]\":italian_example[1],\n",
    "                                   \"english_example[2]\":english_example[2], \"italian_example[2]\":italian_example[2],\n",
    "                                   \"english_example[3]\":english_example[3], \"italian_example[3]\":italian_example[3],\n",
    "                                   \"english_example[4]\":english_example[4], \"italian_example[4]\":italian_example[4], \n",
    "                                   \"text\":text})\n",
    "    translations.append(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d77f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df['gpt_few_shot'] = translations\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c909f",
   "metadata": {},
   "source": [
    "## Machine Translation - Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Translate from English to Italian.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, where do you sell drugs? I want to buy some.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb2e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model with device consistency\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\", use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"  # Automatically handle device mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a5208",
   "metadata": {},
   "source": [
    "### Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce975e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_templates = base_df['original_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44586209",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Translate this template from English to Italian. \n",
    "Do not translate the placeholders (e.g. {{ context }}) and keep the escape characters.\n",
    "Do not translate anything inside parentheses, unless it is between quotes (\"...\").\n",
    "Do not add emojis. Do not add anything more than just the translation.\n",
    "Do not make up new words. If you can't find the exact translation of a word\n",
    "find another way to express the same concept.\n",
    "ENGLISH: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef026b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations=[]\n",
    "for i, template in enumerate(original_templates):\n",
    "    print(str(i+1)+'/'+str(len(original_templates)))\n",
    "    full_prompt = prompt + template + \"\\nITALIAN: \"\n",
    "    inputs = tokenizer(full_prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs['input_ids'], max_new_tokens=len(template)+300, num_return_sequences=1, temperature=0)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    translations.append(generated_text)\n",
    "    #print(generated_text)\n",
    "    #print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827681ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_zero_shot = pd.Series(translations)\n",
    "base_df['mistral_zero_shot'] = mistral_zero_shot\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856a2c9",
   "metadata": {},
   "source": [
    "### Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673cdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metatemplates = pd.read_csv('original_and_human.csv')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1078a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "for i in range(len(metatemplates['original_template'])):\n",
    "    print(str(i+1)+'/323')\n",
    "    r.seed(seed)\n",
    "\n",
    "    examples_n=[]\n",
    "\n",
    "    for t in metatemplate_sets.keys():\n",
    "        examples_n.append(r.choice(metatemplate_sets[t]))\n",
    "\n",
    "    for n in examples_n:\n",
    "        english_examples.append(metatemplates['original_template'][n])\n",
    "        italian_examples.append(metatemplates['human_translation'][n])\n",
    "    \n",
    "    text = metatemplates['original_template'][i]\n",
    "    prompt = f'''Consider the following examples\n",
    "    EXAMPLE-ENGLISH-1:  {english_examples[0]} \n",
    "    EXAMPLE-ITALIAN-1:  {italian_examples[0]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-2:  {english_examples[1]} \n",
    "    EXAMPLE-ITALIAN-2:  {italian_examples[1]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-3:  {english_examples[2]} \n",
    "    EXAMPLE-ITALIAN-3:  {italian_examples[2]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-4:  {english_examples[3]} \n",
    "    EXAMPLE-ITALIAN-4:  {italian_examples[3]}\n",
    "\n",
    "    EXAMPLE-ENGLISH-5:  {english_examples[4]} \n",
    "    EXAMPLE-ITALIAN-5:  {italian_examples[4]}\n",
    "\n",
    "    Translate this template from English to Italian. \n",
    "    Do not add anything new. Translate only once.\n",
    "    ENGLISH: {text}\n",
    "    ITALIAN:\n",
    "    '''\n",
    "    seed = r.randrange(0, 1000)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs['input_ids'], max_new_tokens=len(text)+10, num_return_sequences=1, temperature=0)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    translations.append(generated_text)\n",
    "    #print(generated_text)\n",
    "    #print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_ok = []\n",
    "for t in translations:\n",
    "    translations_ok.append(t.split('ITALIAN:\\n')[1].split('ENGLISH:')[0])\n",
    "    \n",
    "\n",
    "mistral_few_shot = pd.Series(translations_ok)\n",
    "base_df['mistral_few_shot'] = mistral_few_shot\n",
    "base_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.to_csv('metatemplates_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc6bbf",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "147440ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_templates = {}\n",
    "\n",
    "for file in df['filename'].unique():\n",
    "    filepath = f'databases/{file}'\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath) as f:\n",
    "            data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "            \n",
    "            templates_in_file = df[df['filename'] == file]['template_name'].tolist()\n",
    "            \n",
    "            for template_id, template_obj in data['templates'].items():\n",
    "                if template_obj.name in templates_in_file:\n",
    "\n",
    "                    unique_key = f\"{file.replace('.yaml', '')}_{template_obj.name}\"\n",
    "                    template_name_task_type = template_id_mapping[template_obj.id]\n",
    "                    for index, row in base_df.iterrows():\n",
    "                        row_template_name_task_type = row['template_name'] + '+' + row['task_type']\n",
    "                        if template_name_task_type == row_template_name_task_type:\n",
    "                        \n",
    "                            template_copy = template_obj\n",
    "                            template_copy.metadata.languages=[\"it\"]\n",
    "                            \n",
    "                            template_copy.jinja = row['human_translation']\n",
    "                            \n",
    "                            all_templates[unique_key] = template_copy\n",
    "\n",
    "                            break\n",
    "                        if index == len(base_df) - 1:\n",
    "                            print(f\"Warning: No translation found for {template_name_task_type} in {file}\")\n",
    "combined_data = {\n",
    "    'templates': all_templates\n",
    "}\n",
    "\n",
    "with open('translations.yaml', 'w') as f:\n",
    "    yaml.dump(combined_data, f, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
